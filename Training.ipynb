{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "OkVmSYSLWdm2",
    "outputId": "e8611a13-5066-49cc-c822-eada34ea8412"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!pip install tensorflow==2.0\\n!pip install tensorflow_hub\\n!pip install bert-for-tf2\\n!pip install sentencepiece'"
      ]
     },
     "execution_count": 2,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''!pip install tensorflow==2.0\n",
    "!pip install tensorflow_hub\n",
    "!pip install bert-for-tf2\n",
    "!pip install sentencepiece'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "SbtC2O89XiMR",
    "outputId": "a99568d2-8328-4d33-83c4-112e841519db"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF version:  2.0.0\n",
      "Hub version:  0.7.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "print(\"TF version: \", tf.__version__)\n",
    "print(\"Hub version: \", hub.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cdpDj5ABXlIn"
   },
   "outputs": [],
   "source": [
    "import bert\n",
    "from tensorflow.keras.models import Model       # Keras is the new high level API for TensorFlow\n",
    "from tensorflow import keras\n",
    "import math\n",
    "import re\n",
    "import numpy as np\n",
    "import random "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5PnvCRBOZsuR"
   },
   "outputs": [],
   "source": [
    "checkpoint_path = '/content/model.ckpt'\n",
    "sentenceFile = '/content/sentences.txt'\n",
    "treeFile = '/content/tree_mod.txt'\n",
    "\n",
    "max_seq_length = 128  # Your choice here.\n",
    "epochs = 1\n",
    "#textRegEx = \"[a-zA-Z1-9!?@:&\\+{}\\[\\]\\.,\\$/\\\"-]+\"\n",
    "#tagRegEx = \"[A-Z!?@:&\\+{}\\[\\]\\.,\\$/\\\"-]+\"\n",
    "#regEx = tagRegEx+\"\\s\"+textRegEx\n",
    "#print(regEx)\n",
    "# \"$+.[]\n",
    "nextId = 0\n",
    "maxVal = 1000\n",
    "minVal = -1\n",
    "bertOutDim = 768\n",
    "#totalTags = 45\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "O_hph--BSw76"
   },
   "outputs": [],
   "source": [
    "label_dict = {'-NONE':1, 'PDT': 2, 'PAP': 3, 'POP': 4, 'A-C': 5, 'CDC': 6, 'IMSAI': 7, 'NP-PRD': 8, 'ADVP-TMP': 9, 'NP-LOC': 10, 'NESB': 11, 'LRB': 12, 'NP-VOC': 13, 'NBC': 14, 'III': 15, 'OK': 16, 'SBAR-LOC-PRD': 17, 'RATE': 18, 'EST': 19, 'MD': 20, 'GHS': 21, 'LANDOR': 22, 'RP': 23, 'C': 24, 'PP-PUT': 25, 'ADVP-LOC-CLR': 26, 'JJS': 27, 'FTC': 28, 'BMP': 29, 'SYM': 30, 'COPPER': 31, 'G': 32, 'LONDON': 33, 'N': 34, 'WTVJ': 35, 'EC': 36, 'ADJP': 37, 'COMMUNICATIONS': 38, 'CS': 39, 'NCR': 40, 'FALL': 41, 'PLO': 42, 'CAT': 43, 'DDB': 44, 'E': 45, 'IBC': 46, 'CIA': 47, 'V': 48, 'FT': 49, 'PLC': 50, 'PRP': 51, 'NX-TTL': 52, 'NNPS': 53, 'BIRDS': 54, 'DT': 55, 'VBZ': 56, 'SEC': 57, 'FUNDS': 58, 'RATES': 59, 'AND': 60, 'ECONOMIC': 61, 'LTV': 62, 'NP-TPC': 63, 'ROGERS': 64, 'FAMILY': 65, 'PP-LOC-CLR-TPC': 66, 'A-D': 67, 'RNR': 68, 'SBARQ-NOM': 69, 'ADR': 70, 'NP-LGS': 71, 'SALARIES': 72, 'ASSOCIATES': 73, 'MONEY': 74, 'LST': 75, 'ADVP-EXT': 76, 'S-SBJ': 77, 'B': 78, 'ADVP-PRD': 79, 'RRC': 80, 'ADVP-PRP': 81, 'WHADJP': 82, 'JUDICIAL': 83, 'PRODUCTS': 84, 'DIALING': 85, 'PP-PRD-LOC': 86, 'OVER': 87, 'ADVP-PRD-LOC': 88, 'FRAG-TPC': 89, 'SQ-TPC': 90, 'SBAR-NOM-SBJ': 91, 'AGREES': 92, 'ADVP-TMP-CLR': 93, 'F': 94, 'OTC': 95, 'FRAG': 96, 'TRIAL': 97, 'LYNCH': 98, 'ADVP-CLR': 99, 'HUD': 100, 'PP-TTL': 101, 'ADJP-TMP': 102, 'LS': 103, 'DES': 104, 'USA': 105, 'US': 106, 'UCP-PRD': 107, 'S-CLF-TPC': 108, 'ASSETS': 109, 'NL': 110, 'JUDGE': 111, 'SBARQ-TPC': 112, 'SBAR': 113, 'S-PRP-PRD': 114, 'NASD': 115, 'NP-TMP': 116, 'MORTGAGE': 117, 'ABA': 118, 'CONJP': 119, 'CHANGED': 120, 'VBD': 121, 'AT': 122, 'ADVP': 123, 'TRANSPLANT': 124, 'PP-CLR': 125, 'PP-BNF': 126, 'VB': 127, 'GRAINS': 128, 'POTABLES': 129, 'UAL': 130, 'WRB': 131, 'THREE': 132, 'ABORTION': 133, 'NOT': 134, 'PP-TMP-PRD': 135, 'WHPP': 136, 'IBM': 137, 'S-TTL': 138, 'IRA': 139, 'NP-HLN': 140, 'FRAG-TTL-SBJ': 141, 'NEC': 142, 'CBS': 143, 'NBI': 144, 'ADVP-MNR': 145, 'A': 146, 'DOT': 147, 'SINV-TPC': 148, 'UBS': 149, 'SALT': 150, 'PP-DIR': 151, 'CD': 152, 'PPA': 153, 'S-TMP': 154, 'ENERGY': 155, 'SERVICES': 156, 'SAT': 157, 'ADJP-PRD': 158, 'TEXAS': 159, 'TWO': 160, 'MEDICINE': 161, 'SBAR-CLR': 162, 'FAX': 163, 'PORTING': 164, 'PS': 165, 'SBAR-MNR': 166, 'FRAG-HLN': 167, 'UCP': 168, 'SBAR-TMP': 169, 'USIA': 170, 'BALLOT': 171, 'MERRILL': 172, 'GROWTH': 173, 'S-MNR': 174, 'OSHA': 175, 'WP': 176, 'FW': 177, 'BANKERS': 178, 'PP-PRP': 179, 'ADVP-LOC': 180, 'TRS': 181, 'PP-CLR-LOC': 182, 'EXP': 183, 'INS': 184, 'S-PRP-CLR': 185, 'INTER-TEL': 186, 'SWITCHING': 187, 'UNION': 188, 'PAPER': 189, 'INTJ': 190, 'ORTEGA': 191, 'LOAN': 192, 'DD': 193, 'AG': 194, 'UH': 195, 'RULING': 196, 'METALS': 197, 'PP-EXT': 198, 'ADJP-PRD-TPC': 199, 'NP-CLR': 200, 'WAR': 201, 'II': 202, 'SINV': 203, 'VBG': 204, 'SBAR-LOC': 205, 'CEO': 206, 'CLEARS': 207, 'IRS': 208, 'GOODY': 209, 'NAC': 210, 'USX': 211, 'TRIMMING': 212, 'TREASURY': 213, 'CSV': 214, 'X': 215, 'AN': 216, 'LSI': 217, 'DISCOUNT': 218, 'SBAR-PRD': 219, 'WHNP': 220, 'IX': 221, 'COMPUTERS': 222, 'PP-LOC-CLR': 223, 'GM': 224, 'NATIONAL': 225, 'ADVP-DIR': 226, 'YWCA': 227, 'CC': 228, 'NP-MNR': 229, 'OF': 230, 'VP-TPC': 231, 'EVERYONE': 232, 'H': 233, 'S-NOM-PRD': 234, 'TIRED': 235, 'ADVP-PRD-TPC': 236, 'X-HLN': 237, 'COLLECTING': 238, 'WPP': 239, 'S-HLN': 240, 'INQUIRY': 241, 'RCB': 242, 'NNP': 243, 'SBAR-NOM-PRD': 244, 'PP-LOC-TPC': 245, 'WAFA': 246, 'RB': 247, 'POS': 248, 'FIRST': 249, 'K': 250, 'NNS': 251, 'NP-TMP-HLN': 252, 'JJR': 253, 'LIBOR': 254, 'FERC': 255, 'TO': 256, 'WHADVP': 257, 'ASSOCIATION': 258, 'WTD': 259, 'DSM': 260, 'NAC-LOC': 261, 'INTERBANK': 262, 'SBAR-ADV': 263, 'PP-TPC': 264, 'LCB': 265, 'TV': 266, 'S-CLF': 267, 'CALL': 268, 'IOU': 269, 'PP-TMP': 270, 'ADJP-CLR': 271, 'Q': 272, 'FRAG-ADV': 273, 'S-NOM': 274, 'RBS': 275, 'SDI': 276, 'EURODOLLARS': 277, 'SHAREDATA': 278, 'SOYBEANS': 279, 'LATE': 280, 'NEW': 281, 'S-TPC': 282, 'NONE': 283, 'ACQUISITION': 284, 'RRB': 285, 'ISSUES': 286, 'PP-MNR': 287, 'ON': 288, 'BTR': 289, 'DIAPER': 290, 'S-CLR': 291, 'NP-EXT': 292, 'CAMPAIGN': 293, 'ASLACTON': 294, 'PP-LGS': 295, 'PP-TMP-CLR': 296, 'NTG': 297, 'NP-TMP-CLR': 298, 'PP-PRD': 299, 'YMCA': 300, 'APPEARS': 301, 'P': 302, 'READY': 303, 'W': 304, 'PRIME': 305, 'BILLS': 306, 'S-ADV': 307, 'Z': 308, 'SCI': 309, 'U': 310, 'PRT': 311, 'ENDED': 312, 'D': 313, 'TROUBLES': 314, 'ADVP-LOC-PRD': 315, 'INTERPUBLIC': 316, 'PP-DTV': 317, 'FOREIGN': 318, 'PHOTOGRAPH': 319, 'NP-SBJ': 320, 'ACCOUNT': 321, 'UPHELD': 322, 'PP-LOC-PRD': 323, 'FBI': 324, 'NAC-TMP': 325, 'ADVP-LOC-PRD-TPC': 326, 'ADVP-DIR-TPC': 327, 'MITI': 328, 'S-PRP': 329, 'CORP': 330, 'SBARQ': 331, 'NCNB': 332, 'NP': 333, 'GMAC': 334, 'ACCEPTANCES': 335, 'PP': 336, 'NP-TTL-PRD': 337, 'IT': 338, 'SBAR-PRP': 339, 'PP-DIR-CLR': 340, 'ADJP-ADV': 341, 'VP': 342, 'DOONESBURY': 343, 'VBN': 344, 'NP-TMP-TPC': 345, 'JJ': 346, 'OFFERED': 347, 'ADVP-HLN': 348, 'EX': 349, 'M': 350, 'HOME': 351, 'FEDERAL': 352, 'PRECIOUS': 353, 'UCP-MNR': 354, 'BRAMALEA': 355, 'NP-TTL': 356, 'NN': 357, 'CTB': 358, 'COMMERCIAL': 359, 'GHKM': 360, 'FT-SE': 361, 'NP-PRD-TTL': 362, 'PRN': 363, 'NIH': 364, 'VOA': 365, 'BRIEFS': 366, 'THE': 367, 'S-PRD': 368, 'EXCHANGE': 369, 'NP-ADV': 370, 'PC': 371, 'ICH': 372, 'DEFENSE': 373, 'J': 374, 'SQ': 375, 'SBAR-PRP-PRD': 376, 'O': 377, 'CERTIFICATES': 378, 'CREATOR': 379, 'ADJP-TPC': 380, 'PP-LOC-PRD-TPC': 381, 'SBAR-SBJ': 382, 'ADVP-PUT': 383, 'NYSE': 384, 'NRDC': 385, 'WFRR': 386, 'AC': 387, 'PP-LOC': 388, 'THAT': 389, 'TXO': 390, 'GAF': 391, 'WHAS': 392, 'HHS': 393, 'QP': 394, 'RBR': 395, 'S-NOM-SBJ': 396, 'UCP-PRP': 397, 'DNA': 398, 'AMR': 399, 'UCP-ADV': 400, 'UCP-TMP': 401, 'PETS': 402, 'WDT': 403, 'ADVP-DIR-CLR': 404, 'DEPOSIT': 405, 'T': 406, 'PP-MNR-CLR': 407, 'VBP': 408, 'EEOC': 409, 'L': 410, 'AIDS': 411, 'R': 412, 'IN': 413, 'PTA': 414, 'GOP': 415, 'UCP-LOC-CLR': 416, 'TRUST': 417, 'INGERSOLL-RAND': 418, 'PAPERS': 419, 'RMS': 420, 'NX': 421, 'RBC': 422, 'I': 423, 'Y': 424, 'ITC': 425, 'S': 426, 'NP-TTL-SBJ': 427, 'CTBS': 428, 'SBAR-NOM': 429,'.':430, '!':431, '?':432, '@':433,':':434,'&':435,'+':436,'{':437,'}':438,'[':439,']':440,'$':441,'/':442,'\"':443,'-':444,',':445,'``':446,\"''\":447,'#':448,'ADVP|PRT':449}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "XWnDtdTcUCF2",
    "outputId": "6d1ade32-8f28-468e-fbe2-9def1ca76ca0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "449\n"
     ]
    }
   ],
   "source": [
    "totalTags = len(label_dict)\n",
    "print(totalTags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Qj7wYvvhXxXo"
   },
   "outputs": [],
   "source": [
    "def getBERTModel():\n",
    "    input_word_ids = tf.keras.layers.Input(shape=(max_seq_length,), dtype=tf.int32,name=\"input_word_ids\")\n",
    "    input_mask = tf.keras.layers.Input(shape=(max_seq_length,), dtype=tf.int32,name=\"input_mask\")\n",
    "    segment_ids = tf.keras.layers.Input(shape=(max_seq_length,), dtype=tf.int32,name=\"segment_ids\")\n",
    "\n",
    "    bert_layer = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/1\",trainable=False)\n",
    "    pooled_output, sequence_output = bert_layer([input_word_ids, input_mask, segment_ids])\n",
    "\n",
    "    model = Model(inputs=[input_word_ids, input_mask, segment_ids], outputs=[pooled_output, sequence_output])\n",
    "\n",
    "    # Import tokenizer using the original vocab file\n",
    "    vocab_file = bert_layer.resolved_object.vocab_file.asset_path.numpy()\n",
    "    do_lower_case = bert_layer.resolved_object.do_lower_case.numpy()\n",
    "    FullTokenizer = bert.bert_tokenization.FullTokenizer\n",
    "    tokenizer = FullTokenizer(vocab_file, do_lower_case)\n",
    "\n",
    "    return {'model':model,'tokenizer':tokenizer}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "94f9VPB1YH5g"
   },
   "outputs": [],
   "source": [
    "def get_masks(tokens, max_seq_length):\n",
    "    \"\"\"Mask for padding\"\"\"\n",
    "    #print('len(tokens),max_seq_length)\n",
    "    if len(tokens)>max_seq_length:\n",
    "        raise IndexError(\"Token length more than max seq length!\")\n",
    "    return [1]*len(tokens) + [0] * (max_seq_length - len(tokens))\n",
    "\n",
    "\n",
    "def get_segments(tokens, max_seq_length):\n",
    "    \"\"\"Segments: 0 for the first sequence, 1 for the second\"\"\"\n",
    "    if len(tokens)>max_seq_length:\n",
    "        raise IndexError(\"Token length more than max seq length!\")\n",
    "    segments = []\n",
    "    current_segment_id = 0\n",
    "    for token in tokens:\n",
    "        segments.append(current_segment_id)\n",
    "        if token == \"[SEP]\":\n",
    "            current_segment_id = 1\n",
    "    return segments + [0] * (max_seq_length - len(tokens))\n",
    "\n",
    "\n",
    "def get_ids(tokens, tokenizer, max_seq_length):\n",
    "    \"\"\"Token ids from Tokenizer vocab\"\"\"\n",
    "    token_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "    input_ids = token_ids + [0] * (max_seq_length-len(token_ids))\n",
    "    return input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GRzEQBb_aMlg"
   },
   "outputs": [],
   "source": [
    "def getEmbeddings(model,tokenizer,sentence): \n",
    "    stokens = tokenizer.tokenize(sentence)\n",
    "    #print('sen len:',sentence)\n",
    "    #print('sen len:',len(sentence.split()))\n",
    "    stokens = [\"[CLS]\"] + stokens + [\"[SEP]\"]\n",
    "\n",
    "    input_ids = get_ids(stokens, tokenizer, max_seq_length)\n",
    "    input_masks = get_masks(stokens, max_seq_length)\n",
    "    input_segments = get_segments(stokens, max_seq_length)\n",
    "\n",
    "    pool_embs, all_embs = model.predict([[input_ids],[input_masks],[input_segments]])\n",
    "    # pool_ebmbs is an embeding of CLS token\n",
    "    # all_embs contains embeding for words of input sentence.\n",
    "    return all_embs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jCr-cHjkck15"
   },
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self,lb):\n",
    "        self.label = lb\n",
    "        self.I = maxVal\n",
    "        self.J = minVal\n",
    "        self.child = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "exRc2gyls2wy"
   },
   "outputs": [],
   "source": [
    "class stackEle:\n",
    "    def __init__(self,st,nd):\n",
    "        self.tag = st\n",
    "        self.nd = nd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8Zdj1O6ss9VC"
   },
   "outputs": [],
   "source": [
    "def top(stack):\n",
    "    return stack[len(stack)-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "T0jbPyEGcl0A",
    "outputId": "6a15499e-c0e0-476c-a91f-2b13b368d05c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'def getLeafIndices(regEx,tree):\\n    iter = re.finditer(regEx, tree)\\n    indices = [m.start(0) for m in iter]\\n    return indices'"
      ]
     },
     "execution_count": 14,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''def getLeafIndices(regEx,tree):\n",
    "    iter = re.finditer(regEx, tree)\n",
    "    indices = [m.start(0) for m in iter]\n",
    "    return indices'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Cd5tG73tcofv"
   },
   "outputs": [],
   "source": [
    "def getLabel(tree,treeLen,start):\n",
    "    label = ''\n",
    "    i = start\n",
    "    while(i<treeLen and tree[i] != ' ' and tree[i]!=')'):\n",
    "        label = label+tree[i]\n",
    "        i = i + 1\n",
    "    return [label,i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LPWLZekKS5d1"
   },
   "outputs": [],
   "source": [
    "def labelToid(label=None, label_dict=label_dict):\n",
    "    if label is not None:\n",
    "        raw_label = re.search('(.*?)[-0-9]*$', label).group(1)\n",
    "        n = len(raw_label)\n",
    "\n",
    "        if n>1 and raw_label[n-1] == '=':\n",
    "            raw_label = raw_label[:n-1]\n",
    "        elif n>1 and raw_label[n-1] == '$':\n",
    "            raw_label = raw_label[:n-1]\n",
    "        elif n>1 and raw_label[0] == '-':\n",
    "            raw_label = raw_label[1:]\n",
    "\n",
    "        return label_dict[raw_label]\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "-c1fcacjcrYX",
    "outputId": "642ddbc4-61a4-477c-8be3-401820edaf2b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"def generateChild(tree,treeLen,i,head,indices,mat):\\n    global nextId\\n    out = getLabel(tree,treeLen,i)\\n    #print(out)\\n    temp = Node(out[0])\\n    if i in indices:\\n        temp.I = nextId\\n        temp.J = nextId\\n        nextId = nextId + 1\\n        while(i<treeLen and tree[i] != ')'):\\n            i = i + 1\\n        i = i + 1\\n        mat[temp.I][temp.J] = labelToid(temp.label,label_dict)      #------------------------------\\n        #mat[temp.I][temp.J] = 40\\n        head.child.append(temp)\\n        return i\\n    else: \\n        i = out[1]\\n        while tree[i] == '(':\\n            ind = generateChild(tree,treeLen,i+1,temp,indices,mat)\\n            i = ind\\n            newChild = temp.child[len(temp.child)-1]\\n            #print(temp.I,newChild.I)\\n            temp.I = min(temp.I,newChild.I)\\n            temp.J = max(temp.J,newChild.J)\\n        i = i + 1\\n        mat[temp.I][temp.J] = labelToid(temp.label,label_dict) #-------------------------------\\n        #mat[temp.I][temp.J] = 40\\n        head.child.append(temp)\\n        return i\""
      ]
     },
     "execution_count": 17,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''def generateChild(tree,treeLen,i,head,indices,mat):\n",
    "    global nextId\n",
    "    out = getLabel(tree,treeLen,i)\n",
    "    #print(out)\n",
    "    temp = Node(out[0])\n",
    "    if i in indices:\n",
    "        temp.I = nextId\n",
    "        temp.J = nextId\n",
    "        nextId = nextId + 1\n",
    "        while(i<treeLen and tree[i] != ')'):\n",
    "            i = i + 1\n",
    "        i = i + 1\n",
    "        mat[temp.I][temp.J] = labelToid(temp.label,label_dict)      #------------------------------\n",
    "        #mat[temp.I][temp.J] = 40\n",
    "        head.child.append(temp)\n",
    "        return i\n",
    "    else: \n",
    "        i = out[1]\n",
    "        while tree[i] == '(':\n",
    "            ind = generateChild(tree,treeLen,i+1,temp,indices,mat)\n",
    "            i = ind\n",
    "            newChild = temp.child[len(temp.child)-1]\n",
    "            #print(temp.I,newChild.I)\n",
    "            temp.I = min(temp.I,newChild.I)\n",
    "            temp.J = max(temp.J,newChild.J)\n",
    "        i = i + 1\n",
    "        mat[temp.I][temp.J] = labelToid(temp.label,label_dict) #-------------------------------\n",
    "        #mat[temp.I][temp.J] = 40\n",
    "        head.child.append(temp)\n",
    "        return i'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "zV1PHxS1cuVH",
    "outputId": "68533872-9870-450a-b5c6-41c7382af4c8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"def generateTree(tree,mat):\\n    #print(tree)\\n    global nextId\\n    treeLen = len(tree)\\n    indices = getLeafIndices(regEx,tree)\\n    i = 0\\n    i = i + 1\\n    nextId = 0\\n    #head = None\\n    while(i<treeLen):\\n        out = getLabel(tree,treeLen,i)\\n        #print(out)\\n        head = Node(out[0])\\n        i = out[1]\\n        while tree[i] == '(':\\n            ind = generateChild(tree,treeLen,i+1,head,indices,mat)\\n            i = ind\\n            newChild = head.child[len(head.child)-1]\\n            #print(temp.I,newChild.I)\\n            head.I = min(head.I,newChild.I)\\n            head.J = max(head.J,newChild.J)\\n        i = i + 1\\n        mat[head.I][head.J] = labelToid(head.label,label_dict)    #-----------------------\\n        #mat[head.I][head.J] = 40\""
      ]
     },
     "execution_count": 18,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''def generateTree(tree,mat):\n",
    "    #print(tree)\n",
    "    global nextId\n",
    "    treeLen = len(tree)\n",
    "    indices = getLeafIndices(regEx,tree)\n",
    "    i = 0\n",
    "    i = i + 1\n",
    "    nextId = 0\n",
    "    #head = None\n",
    "    while(i<treeLen):\n",
    "        out = getLabel(tree,treeLen,i)\n",
    "        #print(out)\n",
    "        head = Node(out[0])\n",
    "        i = out[1]\n",
    "        while tree[i] == '(':\n",
    "            ind = generateChild(tree,treeLen,i+1,head,indices,mat)\n",
    "            i = ind\n",
    "            newChild = head.child[len(head.child)-1]\n",
    "            #print(temp.I,newChild.I)\n",
    "            head.I = min(head.I,newChild.I)\n",
    "            head.J = max(head.J,newChild.J)\n",
    "        i = i + 1\n",
    "        mat[head.I][head.J] = labelToid(head.label,label_dict)    #-----------------------\n",
    "        #mat[head.I][head.J] = 40'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "su4kdj_XsMRx"
   },
   "outputs": [],
   "source": [
    "def generateTree(tree,mat):\n",
    "    global nextId\n",
    "    \n",
    "    nextId = 0\n",
    "    stack = []\n",
    "    treeLen = len(tree)\n",
    "    i = 1\n",
    "    \n",
    "    label,ind = getLabel(tree,treeLen,i)\n",
    "    i = ind\n",
    "    ele = stackEle(label,Node(label))\n",
    "    stack.append(ele)\n",
    "\n",
    "    while i<treeLen-1:\n",
    "        #print(i)\n",
    "        if tree[i] == '(':\n",
    "            stack.append(stackEle('(',None))\n",
    "            i = i + 1\n",
    "        elif tree[i] == ')':\n",
    "            temp = []\n",
    "            while top(stack).tag != '(':\n",
    "                tp = top(stack)\n",
    "                temp.append(tp)\n",
    "                stack.pop()\n",
    "            stack.pop()\n",
    "            if len(temp) == 1:\n",
    "                tp = top(stack).nd\n",
    "                newChild = temp[0].nd\n",
    "                mat[newChild.I][newChild.J] = labelToid(newChild.label,label_dict)      #--------------------------\n",
    "                tp.I = min(tp.I,newChild.I)\n",
    "                tp.J = max(tp.J,newChild.J)\n",
    "                tp.child.append(newChild)\n",
    "            else:\n",
    "                tp = top(stack).nd\n",
    "                newChild = temp[1].nd\n",
    "                newChild.I = nextId\n",
    "                newChild.J = nextId\n",
    "                mat[newChild.I][newChild.J] = labelToid(newChild.label,label_dict)      #--------------------------\n",
    "                nextId = nextId + 1\n",
    "                tp.I = min(tp.I,newChild.I)\n",
    "                tp.J = max(tp.J,newChild.J)\n",
    "                tp.child.append(newChild)\n",
    "            i = i + 1\n",
    "        elif tree[i] == ' ':\n",
    "            i = i + 1\n",
    "        else:\n",
    "            label,ind = getLabel(tree,treeLen,i)\n",
    "            i = ind\n",
    "            ele = stackEle(label,Node(label))\n",
    "            stack.append(ele)\n",
    "\n",
    "    tp = top(stack).nd\n",
    "    stack.pop()\n",
    "    mat[tp.I][tp.J] = labelToid(tp.label,label_dict)     #--------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IdgOqYh8eDU6"
   },
   "outputs": [],
   "source": [
    "def genSpanEncode(embs,i,j):\n",
    "    vi = embs[i]\n",
    "    vj = embs[j]\n",
    "\n",
    "    fi = vi[::2]\n",
    "    bi = vi[1::2]\n",
    "    fj = vj[::2]\n",
    "    bj = vj[1::2]\n",
    "\n",
    "    spanEncode = np.concatenate(((fi - fj), (bi - bj)), axis=0)\n",
    "    #print(spanEncode.shape)\n",
    "    return spanEncode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "teomEZOcEa9q"
   },
   "outputs": [],
   "source": [
    "def getGroundTruth(id):\n",
    "    gt = [0]*(id-1) + [1] + [0]*(totalTags-id)\n",
    "    #print(len(gt))\n",
    "    return np.asarray(gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Cu3ViEw2zh8X"
   },
   "outputs": [],
   "source": [
    "def getSTrData(model,tokenizer,sentence,tree):\n",
    "    length = len(sentence.split())\n",
    "    mat = [[0 for i in range(length)] for i in range(length)]\n",
    "    generateTree(tree,mat)\n",
    "    #print(mat)\n",
    "    embs = getEmbeddings(model,tokenizer,sentence)\n",
    "\n",
    "    trainX = np.asarray([])\n",
    "    trainY = np.asarray([])\n",
    "    for i in range(length):\n",
    "        for j in range(i,length):\n",
    "            spanij = genSpanEncode(embs,i,j)\n",
    "            #----- It will remove all 'UNK' tag.----------------\n",
    "            if mat[i][j] == 0:\n",
    "              '''num = random.randrange(0, 100,1)\n",
    "              if num > 25:'''\n",
    "              continue\n",
    "            #-----------------------------------------------------------------------\n",
    "            GTij = getGroundTruth(mat[i][j])\n",
    "            if trainX.shape[0] == 0:\n",
    "                trainX = np.asarray([spanij])\n",
    "                trainY = np.asarray([GTij])\n",
    "            else:\n",
    "                trainX = np.append(trainX,[spanij],axis=0)\n",
    "                trainY = np.append(trainY,[GTij],axis=0)\n",
    "    return trainX,trainY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HT6hs5xSEiY0"
   },
   "outputs": [],
   "source": [
    "def getTrainingData(model,tokenizer,nSentences,nTrees):\n",
    "    trainX = np.asarray([])\n",
    "    trainY = np.asarray([])\n",
    "    n = len(nSentences)\n",
    "    for i in range(n):             #--------------------------------------\n",
    "        if i%100 == 0:\n",
    "          print( 'Processing ',i,' out of ',n)\n",
    "        senLen = len(nSentences[i].split())\n",
    "        if senLen > 60:\n",
    "          print('Skipped...')\n",
    "          continue\n",
    "        x,y = getSTrData(model,tokenizer,nSentences[i],nTrees[i])\n",
    "        if trainX.shape[0] == 0:\n",
    "            trainX = x\n",
    "            trainY = y\n",
    "        else:\n",
    "            trainX = np.concatenate((trainX, x), axis=0)\n",
    "            trainY = np.concatenate((trainY, y), axis=0)\n",
    "    return trainX,trainY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MJl7DEPSeCAB"
   },
   "outputs": [],
   "source": [
    "def createModel():\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.Dense(256,input_dim=bertOutDim,activation=\"relu\"))\n",
    "    model.add(keras.layers.Dense(totalTags,activation=\"softmax\"))\n",
    "    model.compile(loss=\"categorical_crossentropy\",optimizer=\"adam\",matrics=[\"accuracy\"])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cuCAJXJTcNzx"
   },
   "outputs": [],
   "source": [
    "outModel = getBERTModel()\n",
    "model = outModel['model']\n",
    "tokenizer = outModel['tokenizer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uVHR9cFWYZdC"
   },
   "outputs": [],
   "source": [
    "'''nSentence = [\"short cuts make long delays\",\"short cuts make long delays\"]\n",
    "nTree = ['(S (NP (JJ short)(NNS cuts))(VP (VBP make)(NP (JJ long)(NNS delays))))',\n",
    "         '(S (NP (A-C short)(NNS cuts))(VP (VBP make)(NP (JJ long)(NNS delays))))'\n",
    "         ]'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "v9UxAf7ZsMST",
    "outputId": "c1af04d8-b654-40e8-a309-83d72638d596"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"f = open(sentenceFile, 'r')\\nnSentence = f.read().splitlines()\\nf.close()\""
      ]
     },
     "execution_count": 27,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = open(sentenceFile, 'r')\n",
    "nSentence = f.read().splitlines()\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "cYhGRSG4sMSW",
    "outputId": "c33da61c-bf13-46a1-bff7-8c88b1ce52c5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"f = open(treeFile, 'r')\\nnTree = f.read().splitlines()\\nf.close()\""
      ]
     },
     "execution_count": 28,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = open(treeFile, 'r')\n",
    "nTree = f.read().splitlines()\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "JcLT4C30c2po",
    "outputId": "0a3a45a6-27de-4a6c-d89e-07ab0ba03c9c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing  0  out of  2\n",
      "Training data generated.\n",
      "(18, 768)\n",
      "(18, 449)\n"
     ]
    }
   ],
   "source": [
    "trainX,trainY = getTrainingData(model,tokenizer,nSentence,nTree)\n",
    "print('Training data generated.')\n",
    "print(trainX.shape)\n",
    "print(trainY.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KJnH4LuRG2Hi"
   },
   "outputs": [],
   "source": [
    "#print(trainY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "zbvHrdSe4nKB",
    "outputId": "f3f112e4-d2cd-40bd-dcad-676f6ba88269"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"np.savetxt('trainX.csv',trainX, delimiter=',',fmt='%8.4f')\\nnp.savetxt('trainY.csv',trainY, delimiter=',',fmt='%8.4f')\""
      ]
     },
     "execution_count": 31,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.savetxt('trainX.csv',trainX, delimiter=',',fmt='%8.4f')\n",
    "np.savetxt('trainY.csv',trainY, delimiter=',',fmt='%8.4f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "ixcaTixwo8AE",
    "outputId": "17f20f71-0a19-44d6-9785-17f2800cea63"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 18 samples\n",
      "\n",
      "Epoch 00001: saving model to /content/model.ckpt\n",
      "18/18 [==============================] - 0s 26ms/sample - loss: 6.2203\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f94177e0080>"
      ]
     },
     "execution_count": 34,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = createModel()\n",
    "#model.load_weights(checkpoint_path)\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,save_weights_only=True,verbose=1)\n",
    "model.fit(trainX,trainY,epochs=epochs,callbacks=[cp_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "gIS2sOtZeR84",
    "outputId": "3ea08023-2f58-41d5-e8b0-e2720b8b9d8f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nmodel.evaluate(X_test, y_test)\\n\\nmodel = createModel()\\nmodel.load_weights(checkpoint_path)\\ny_proba = model.predict(X_new)\\n'"
      ]
     },
     "execution_count": 33,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "model.evaluate(X_test, y_test)\n",
    "\n",
    "model = createModel()\n",
    "model.load_weights(checkpoint_path)\n",
    "y_proba = model.predict(X_new)\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Training.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
